# t_pre_clean_soft.py
import json, re, unicodedata
from pathlib import Path
from pythainlp.util import normalize

input_file = Path("data/cleaned_news.jsonl")
output_file = Path("data/ready_for_label_soft.jsonl")
output_file.parent.mkdir(parents=True, exist_ok=True)

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å ---
def soft_clean(text: str) -> str:
    if not text:
        return ""
    # normalize ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    text = unicodedata.normalize("NFC", text)
    text = normalize(text)

    # ‡∏•‡∏ö HTML / emoji
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"[\U00010000-\U0010ffff]", "", text)

    # ‡∏•‡∏ö pattern ‡∏ó‡∏µ‡πà‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÅ‡∏ö‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î)
    remove_patterns = [
        r"‡πÅ‡∏ä‡∏£‡πå‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ.*?(Facebook|Line|Twitter|‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå)",  # ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏ä‡∏£‡πå
        r"‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°.*?‡∏≠‡∏±‡∏•‡∏ö‡∏±‡πâ‡∏°‡∏†‡∏≤‡∏û.*",                             # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°
        r"‡∏î‡∏π‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\s*\d+\s*‡∏†‡∏≤‡∏û.*",                                # ‡∏î‡∏π‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î xx ‡∏†‡∏≤‡∏û
        r"‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì\s*‡∏†‡∏≤‡∏û.*",                                       # ‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏†‡∏≤‡∏û
        r"‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô\s*[:Ôºö]?\s*[‡∏Å-‡∏ÆA-Za-z].*",                       # ‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô
    ]
    for p in remove_patterns:
        text = re.sub(p, "", text)

    # ‡∏•‡∏ö - ‡∏Å ‡∏Å + ‡πÅ‡∏•‡∏∞‡∏û‡∏ß‡∏Å‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á
    text = re.sub(r"-\s*‡∏Å\s*‡∏Å\s*\+", "", text)
    # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
    text = re.sub(r"\s{2,}", " ", text).strip()
    # ‡∏•‡∏ö quote ‡∏ã‡πâ‡∏≥
    text = re.sub(r"[\"‚Äú‚Äù‚Äò‚Äô]+", "", text)

    return text.strip()


def is_valid(text: str) -> bool:
    """‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ó‡∏¥‡πâ‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô"""
    if len(text) < 80:
        return False
    th_chars = len(re.findall(r"[\u0E00-\u0E7F]", text))
    if th_chars / max(len(text), 1) < 0.25:
        return False
    return True


def main():
    print("üßπ ‡πÄ‡∏£‡∏¥‡πà‡∏° soft-clean ‡∏Ç‡πà‡∏≤‡∏ß (‡∏£‡∏±‡∏Å‡∏©‡∏≤ context ‡πÄ‡∏î‡∏¥‡∏°)...")
    total, kept = 0, 0

    with input_file.open(encoding="utf-8") as fin, output_file.open("w", encoding="utf-8") as fout:
        for line in fin:
            total += 1
            try:
                item = json.loads(line)
            except json.JSONDecodeError:
                continue

            text = soft_clean(item.get("text", ""))
            if is_valid(text):
                fout.write(json.dumps({
                    "title": item.get("title", "").strip(),
                    "text": text
                }, ensure_ascii=False) + "\n")
                kept += 1

            if kept % 50 == 0 and kept > 0:
                print(f"   ‚úÖ ‡∏Ñ‡∏•‡∏µ‡∏ô‡πÅ‡∏•‡πâ‡∏ß {kept} ‡∏Ç‡πà‡∏≤‡∏ß (‡∏à‡∏≤‡∏Å {total})")

    print(f"\nüéØ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏° labeling ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {kept}/{total} ‚Üí {output_file}")


if __name__ == "__main__":
    main()
